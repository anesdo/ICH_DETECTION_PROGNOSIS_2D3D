{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f64ca-2a2e-409a-a0a2-f53c512f0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from matplotlib import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(2)\n",
    "\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "class My_Custom_Model:\n",
    "    \n",
    "    \n",
    "    def __init__ (self, I_want_to_train_models, path_csv, path_images, \n",
    "                  img_width, img_height, dataAug,\n",
    "                  loss_function,\n",
    "                  type_image,  model_conv, model_type,                  \n",
    "                  freeze, drop, neurons_last_layer, initializer_seed, metrics, \n",
    "                  model_directory, patience, \n",
    "                  print_report, \n",
    "                  p_to_save):\n",
    "\n",
    "        self.path_csv = path_csv\n",
    "        self.type_image = type_image\n",
    "        self.path_images = path_images\n",
    "        self.img_width= img_width\n",
    "        self.img_height= img_height\n",
    "        self.dataAug= dataAug\n",
    "        self.model_conv= model_conv\n",
    "        self.model_type=model_type\n",
    "        self.freeze= freeze\n",
    "        self.neurons_last_layer= neurons_last_layer\n",
    "        self.initializer_seed= initializer_seed\n",
    "        self.lossf= loss_function\n",
    "        self.metrics= metrics\n",
    "        self.p_to_save= p_to_save\n",
    "        self.model_directory= model_directory\n",
    "        self.patience= patience\n",
    "        self.print_report= print_report\n",
    "        self.I_want_to_train_models=I_want_to_train_models\n",
    "        \n",
    "    \n",
    "    def load_data(self):\n",
    "        if not os.path.exists(self.model_directory + 'Input/'): os.mkdir(self.model_directory + 'Input/')  \n",
    "\n",
    "        if (self.model_type == 'Hybrid' and self.type_image=='2D') or self.type_image=='3D':\n",
    "            \n",
    "            self.partition='Train'\n",
    "            self.X_train_image, self.y_train = self.load_images()\n",
    "            if self.model_type == 'Hybrid': self.X_train_dataf = self.load_dataframe() \n",
    "\n",
    "            self.partition='Validation'\n",
    "            self.X_val_image, self.y_val = self.load_images()\n",
    "            if self.model_type == 'Hybrid': self.X_val_dataf = self.load_dataframe()\n",
    "\n",
    "            self.partition='Test'\n",
    "            self.X_test_image, self.y_test  = self.load_images()\n",
    "            if self.model_type == 'Hybrid':  self.X_test_dataf = self.load_dataframe()\n",
    "            if self.model_type == 'Hybrid': print('[INFO] DEMOGRAFIC DATA: TRAIN SHAPE: '+ str(self.X_train_dataf.shape)+ ' - VAL SHAPE: '+ str(self.X_val_dataf.shape)+ ' - TEST SHAPE: ' + str(self.X_test_dataf.shape))\n",
    "            \n",
    "            print('[INFO] IMAGES: TRAIN SHAPE: '+ str(self.X_train_image.shape)+ ' - VAL SHAPE: '+ str(self.X_val_image.shape)+ ' - TEST SHAPE: ' + str(self.X_test_image.shape))\n",
    "            print('[INFO] LABELS: TRAIN SHAPE: '+ str(self.y_train.shape)+ ' - VAL SHAPE: '+ str(self.y_val.shape)+ ' - TEST SHAPE: ' + str(self.y_test.shape))\n",
    "        \n",
    "        if (self.model_type == 'Images' and self.type_image=='2D'):\n",
    "            self.partition='Train'\n",
    "            self.train_generator = self.load_images_ImageDataGenerator()\n",
    "            \n",
    "            self.partition='Validation'\n",
    "            self.val_generator = self.load_images_ImageDataGenerator()\n",
    "\n",
    "            self.partition='Test'\n",
    "            self.test_generator  = self.load_images_ImageDataGenerator()\n",
    "        \n",
    "            \n",
    "        \n",
    "    def load_images_ImageDataGenerator(self):\n",
    "        \n",
    "        if self.partition == 'Train':\n",
    "            self.csv = pd.read_csv(self.path_csv + 'TRAIN1_NUEVOS.csv', sep=',')\n",
    "\n",
    "        elif self.partition == 'Validation':\n",
    "            self.csv = pd.read_csv(self.path_csv +'VAL1_NUEVOS.csv', sep=',')\n",
    "            \n",
    "        else:\n",
    "            self.csv = pd.read_csv(self.path_csv + 'TEST15_NUEVOS.csv', sep=',') \n",
    "            self.csv_test = self.csv \n",
    "            \n",
    "        self.csv['Label']=self.csv['Label'].astype(str)\n",
    "            \n",
    "                \n",
    "        self.class_mode='binary' if self.neurons_last_layer < 2 else 'categorical'\n",
    "        \n",
    "        if self.dataAug == True and self.partition == 'Train':\n",
    "            datagen = ImageDataGenerator(rescale=1./255, rotation_range=90, horizontal_flip=False, brightness_range=[0.3,0.9])\n",
    "        else:\n",
    "            datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        self.shuffle = True if self.partition == 'Train' else False\n",
    "        generator = datagen.flow_from_dataframe(self.csv, directory=self.path_images, x_col='Patient',\n",
    "                                                    y_col='Label', batch_size=self.batch_size, class_mode= self.class_mode,\n",
    "                                                    color_mode='rgb', target_size=(self.img_width, self.img_height),\n",
    "                                                    shuffle=self.shuffle)\n",
    "        return generator\n",
    "        \n",
    "    def load_images(self):\n",
    "        \n",
    "        if self.type_image=='3D':\n",
    "            if self.partition == 'Train':\n",
    "                self.csv = pd.read_csv(self.path_csv + 'TRAIN_PATIENT_random_normalizado.csv', sep=',')\n",
    "\n",
    "            elif self.partition == 'Validation':\n",
    "                self.csv = pd.read_csv(self.path_csv +'VAL_PATIENT_random_normalizado.csv', sep=',')\n",
    "            else:\n",
    "                self.csv = pd.read_csv(self.path_csv + 'TEST15_PATIENT_NUEVO_random_normalizado.csv', sep=',') \n",
    "                self.csv_test = self.csv \n",
    "                \n",
    "        elif self.type_image=='2D':\n",
    "            if self.partition == 'Train':\n",
    "                self.csv = pd.read_csv(self.path_csv + 'TRAIN1_NUEVOS.csv', sep=',')\n",
    "\n",
    "            elif self.partition == 'Validation':\n",
    "                self.csv = pd.read_csv(self.path_csv +'VAL1_NUEVOS.csv', sep=',')\n",
    "            \n",
    "            else:\n",
    "                self.csv = pd.read_csv(self.path_csv + 'TEST15_NUEVOS.csv', sep=',') \n",
    "                self.csv_test =  pd.read_csv(self.path_csv + 'TEST15_NUEVOS.csv', sep=',')\n",
    "            \n",
    "        X = []\n",
    "        for filename in self.csv['Patient']:\n",
    "            if self.type_image == '3D':\n",
    "                img_data = np.load(self.path_images + filename +'.npy')\n",
    "                img_data = self.resize(img_data)\n",
    "                    \n",
    "            elif self.type_image == '2D':\n",
    "                # load image\n",
    "                img_data = image.imread(self.path_images + filename)\n",
    "                img_data = self.resize(img_data)\n",
    "                    \n",
    "            X.append(img_data)\n",
    "\n",
    "        X = np.expand_dims(np.asarray(X, dtype=np.float64), axis=4) if self.type_image == '3D' else np.stack((X,X,X), axis=3).astype('float64')\n",
    "            \n",
    "        return X, self.csv['Label']\n",
    "    \n",
    "    \n",
    "    def load_dataframe(self):\n",
    "        for i in range(len(self.csv['Patient'])): \n",
    "            self.csv.loc[i, 'PatientAge'] = round((self.csv['PatientAge'][i]-min(self.csv['PatientAge'])) / (max(self.csv['PatientAge']) - min(self.csv['PatientAge'])),2)\n",
    "        self.csv_data = self.csv\n",
    "        self.csv_data=self.csv_data.drop(['Patient','Label'], axis=1)\n",
    "        self.csv_data.to_csv(self.model_directory + 'Input/'+self.partition+'_data.csv', index = False)\n",
    "        return np.asarray(self.csv_data).astype('float64')\n",
    "\n",
    "\n",
    "    def resize(self, img_data):    \n",
    "        if self.type_image=='3D':\n",
    "            n,m,l=img_data.shape\n",
    "            img_p=list(img_data)\n",
    "\n",
    "            matriz_float = np.zeros((m,l))\n",
    "            matriz_float = np.float32(matriz_float)\n",
    "            self.depth=45\n",
    "            for ind in range(n,self.depth):\n",
    "                img_p.append(matriz_float)\n",
    "            img_p=np.array(img_p)\n",
    "\n",
    "\n",
    "            n,m,l=img_p.shape\n",
    "            img_data=np.zeros([self.img_width,self.img_height, n])\n",
    "\n",
    "            for i in range(0,n):\n",
    "                img_data[:,:,i]=cv2.resize(img_p[i,:,:],(self.img_width,self.img_height,))\n",
    "                \n",
    "        elif self.type_image == '2D':\n",
    "            img_data = cv2.resize(img_data, (self.img_width, self.img_height))\n",
    "            img_data = img_data/255.\n",
    "            if len(img_data.shape) == 3: img_data=img_data[:,:,0]\n",
    "\n",
    "        return img_data\n",
    "    \n",
    "    \n",
    "    def get_model_CSIC2D(self):\n",
    "        inputs = keras.Input((self.img_width, self.img_height, 3))    \n",
    "        x = keras.layers.Conv2D(filters=16, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed),   activation=\"relu\")(inputs) \n",
    "        x = keras.layers.Conv2D(filters=16, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed),  activation=\"relu\")(x)\n",
    "        x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "        x = keras.layers.Dropout(self.drop)(x)\n",
    "        \n",
    "        x = keras.layers.Conv2D(filters=32, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed),  activation=\"relu\")(x)\n",
    "        x = keras.layers.Conv2D(filters=32, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed),  activation=\"relu\")(x)\n",
    "        x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "        outputs = keras.layers.Conv2D(filters=64, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed), activation=\"relu\", name=\"last_layer\")(x)\n",
    "        self.base_model = keras.Model(inputs, outputs, name=\"CSIC 2D MODEL\")\n",
    "            \n",
    "    \n",
    "    def get_model_CSIC3D(self):    \n",
    "        inputs = keras.Input((self.img_width, self.img_height, self.depth, 1))\n",
    "        x = keras.layers.Conv3D(filters=16, kernel_size=3,  kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed), activation=\"relu\",use_bias=False)(inputs)\n",
    "        x = keras.layers.Conv3D(filters=16, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed), activation=\"relu\",use_bias=False)(x)\n",
    "        x = keras.layers.MaxPool3D(pool_size=2)(x)\n",
    "        x = keras.layers.SpatialDropout3D(self.drop)(x)\n",
    "\n",
    "        x = keras.layers.Conv3D(filters=32, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed), activation=\"relu\",use_bias=False)(x)\n",
    "        x = keras.layers.Conv3D(filters=32, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed), activation=\"relu\",use_bias=False)(x)\n",
    "        x = keras.layers.MaxPool3D(pool_size=2)(x)\n",
    "\n",
    "        outputs = keras.layers.Conv3D(filters=64, kernel_size=3, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed),  activation=\"relu\", name=\"last_layer\",use_bias=False)(x)\n",
    "        self.base_model = keras.Model(inputs, outputs, name=\"CSIC 3D MODEL\")\n",
    "\n",
    "    def base_model(self):        \n",
    "        if self.type_image == '2D':\n",
    "            if self.model_conv == 'VGG16':\n",
    "                self.base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape= (self.img_width, self.img_height, 3)) \n",
    "\n",
    "                \n",
    "                if self.freeze == False:\n",
    "                    for layer in self.base_model.layers:\n",
    "                        layer.trainable = True\n",
    "                    print('No frozen layers')\n",
    "\n",
    "                elif self.freeze == True:\n",
    "                    for layer in self.base_model.layers:\n",
    "                        layer.trainable = False\n",
    "                    print ('All layers frozen')\n",
    "                else:        \n",
    "                    self.freeze = int(input(\"How many layers do you want to freeze?  - (options: 1 - \"+str(len(self.base_model.layers))+\"): \"))\n",
    "                    for layer in self.base_model.layers[0:self.freeze]:\n",
    "                            layer.trainable = False\n",
    "                            print('Layer ' + layer.name + ' frozen...')\n",
    "                    for layer in self.base_model.layers[self.freeze:len(self.base_model.layers)]:\n",
    "                            layer.trainable = True\n",
    "                            print('Layer ' + layer.name + ' unfrozen...')  \n",
    "\n",
    "            elif self.model_conv == 'CSIC':\n",
    "                self.get_model_CSIC2D()\n",
    "                \n",
    "        elif self.type_image == '3D':\n",
    "            if self.model_conv == 'CSIC':\n",
    "                self.get_model_CSIC3D()\n",
    "            else:\n",
    "                print('Model unavailable')\n",
    "                \n",
    "                    \n",
    "    def get_model_hybrid(self):\n",
    "        n, m = self.X_train_dataf.shape\n",
    "        input_data_hybrid = keras.Input(shape=(m,))\n",
    "        y=input_data_hybrid\n",
    "        #y = keras.layers.Dense(10, kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed),activation = 'relu', use_bias=False)(input_data_hybrid) if self.type_image == '3D' else input_data_hybrid\n",
    "        self.model_hybrid = keras.Model(inputs=input_data_hybrid, outputs=y)\n",
    "        self.model_top = keras.layers.concatenate([self.model_top, self.model_hybrid.output])\n",
    "        \n",
    "        \n",
    "    def model_top(self):    \n",
    "        self.model_top = self.base_model.output\n",
    "        \n",
    "        # Definir top model\n",
    "        if self.top_m == 'GMP':\n",
    "            self.model_top = keras.layers.GlobalMaxPooling3D()(self.model_top) if self.type_image == '3D' else keras.layers.GlobalMaxPooling2D()(self.model_top)\n",
    "\n",
    "        elif self.top_m == 'GAP':\n",
    "            self.model_top = keras.layers.GlobalAveragePooling3D()(self.model_top) if self.type_image == '3D' else keras.layers.GlobalAveragePooling2D()(self.model_top)\n",
    "\n",
    "        elif self.top_m == \"FD\":\n",
    "            self.model_top = keras.layers.Flatten()(self.model_top)\n",
    "            self.model_top = keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.HeUniform(seed=self.initializer_seed))(self.model_top)\n",
    "             \n",
    "                \n",
    "        if self.model_type == 'Hybrid': self.get_model_hybrid()\n",
    "    \n",
    "        \n",
    "        if self.neurons_last_layer == 1:\n",
    "            self.model_prediction = keras.layers.Dense(self.neurons_last_layer, activation='sigmoid',\n",
    "                                                kernel_initializer= tf.keras.initializers.GlorotUniform(seed=self.initializer_seed))(self.model_top)\n",
    "                                                                           \n",
    "            if self.lossf == 'categorical_crossentropy':\n",
    "                self.lossf == 'binary_crossentropy'\n",
    "                \n",
    "        if self.neurons_last_layer > 1:\n",
    "            self.model_prediction = keras.layers.Dense(self.neurons_last_layer, activation='softmax',\n",
    "                                                  kernel_initializer= tf.keras.initializers.GlorotUniform(seed=self.initializer_seed))(self.model_top)\n",
    "            if self.lossf == 'binary_crossentropy':\n",
    "                self.lossf == 'categorical_crossentropy'\n",
    "        \n",
    "        #if self.model_type == 'Hybrid': self.model = keras.Model(inputs=[self.base_model.input, self.model_hybrid.input], outputs=self.model_prediction)\n",
    "        self.model = keras.Model(inputs=[self.base_model.input, self.model_hybrid.input], outputs=self.model_prediction) if self.model_type == 'Hybrid' else keras.Model(inputs=self.base_model.input, outputs=self.model_prediction)\n",
    "        self.model.summary()\n",
    "        \n",
    "    def model_compilation (self):\n",
    "        if self.topt == 'SGD':\n",
    "            self.opt= keras.optimizers.SGD (learning_rate= self.lr)\n",
    "        elif self.topt == 'Adam':\n",
    "            self.opt= keras.optimizers.Adam (learning_rate= self.lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        elif self.topt == 'Adadelta':\n",
    "            self.opt= keras.optimizers.Adadelta (learning_rate= self.lr)\n",
    "        elif self.topt == 'Adagrad':\n",
    "            self.opt= keras.optimizers.Adagrad (learning_rate= self.lr)\n",
    "\n",
    "        self.model.compile (optimizer=self.opt, loss=self.lossf, metrics= self.metrics)\n",
    "           \n",
    "            \n",
    "            \n",
    "    def model_fit(self):\n",
    "        self.my_callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=self.patience)]\n",
    "\n",
    "        if (self.model_type == 'Hybrid' and self.type_image == '2D') or self.type_image == '3D':\n",
    "            if self.model_type == 'Hybrid':\n",
    "                train_data = [self.X_train_image, self.X_train_dataf]  \n",
    "                validation_data =  [self.X_val_image, self.X_val_dataf] \n",
    "            elif self.type_image == '3D':\n",
    "                train_data = self.X_train_image \n",
    "                validation_data =  self.X_val_image\n",
    "            self.history = self.model.fit(train_data, self.y_train,\n",
    "                                          batch_size = self.batch_size, epochs = self.epochs,\n",
    "                                          validation_data = (validation_data, self.y_val),\n",
    "                                          callbacks = self.my_callbacks, verbose=1)\n",
    "        elif (self.model_type == 'Images' and self.type_image == '2D'):\n",
    "            self.history = self.model.fit_generator(generator=self.train_generator, steps_per_epoch=self.train_generator.n//self.train_generator.batch_size,\n",
    "                                epochs=self.epochs, verbose=1, validation_data=self.val_generator,\n",
    "                                validation_steps=self.val_generator.n//self.val_generator.batch_size, callbacks=self.my_callbacks)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def plot_learning_curves(self):\n",
    "        # Save curves training\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(self.history.history['accuracy'])\n",
    "        plt.plot(self.history.history['val_accuracy'])\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend(['train', 'val'], loc='best')\n",
    "        plt.savefig(self.path_to_save_metrics + 'LEARNINGCURVE_Accuracy_' + self.model_name + '.png')\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        plt.plot(self.history.history['val_loss'])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend(['train', 'val'], loc='best')\n",
    "        plt.savefig(self.path_to_save_metrics + 'LEARNINGCURVE_Loss_' + self.model_name + '.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def save_images_fpfntptn(self, path_list_tps_fps_fns_tns):\n",
    "        \n",
    "        for idir in ['FNS','FPS','TNS','TPS']:\n",
    "            if not os.path.exists(path_list_tps_fps_fns_tns+'/'+idir+'/'): os.mkdir(path_list_tps_fps_fns_tns+'/'+idir+'/') \n",
    "            csv = pd.read_csv(path_list_tps_fps_fns_tns+'/' + idir +'.csv', sep=',')\n",
    "            if idir=='FNS': \n",
    "                y_true = 1  \n",
    "                y_pred = 0\n",
    "\n",
    "            if idir=='TPS': \n",
    "                y_true = 1  \n",
    "                y_pred = 1\n",
    "            if idir=='FPS' :\n",
    "                y_true = 0 \n",
    "                y_pred = 1\n",
    "\n",
    "            if idir=='TNS':\n",
    "                y_true = 0 \n",
    "                y_pred = 0\n",
    "                \n",
    "            for filename in csv['Marca temporal']:\n",
    "                img_data = Image.open(self.path_images+filename).convert(\"L\")\n",
    "                plt.imshow(img_data, cmap='gray')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.title(filename+' - Sex:'+str(csv['PatientSex'][i])+ ' - Age'+str(csv['PatientAge'][i])+' - Label: '+str(y_true)+' Prediction: '+str(y_pred))\n",
    "                plt.savefig(path_list_tps_fps_fns_tns+'/'+idir+'/'+ filename +'_Sex'+str(csv['PatientSex'][i])+'_Age'+str(csv['PatientAge'][i])+'_Label'+str(y_true)+'_Prediction'+str(y_pred)+'.jpg')\n",
    "                            \n",
    "    def list_fp_fn_tp_tn(self):\n",
    "        \n",
    "        if not os.path.exists(self.path_to_save_metrics+'/LIST_TPS_FPS_FNS_TNS/'): os.mkdir(self.path_to_save_metrics+'/LIST_TPS_FPS_FNS_TNS/')  \n",
    "        path_list_tps_fps_fns_tns=self.path_to_save_metrics+'/LIST_TPS_FPS_FNS_TNS/'+self.model_parameters+'_'+str(self.threshold_plot_confusion_matrix_sex)\n",
    "        if not os.path.exists(path_list_tps_fps_fns_tns): os.mkdir(path_list_tps_fps_fns_tns)  \n",
    "        \n",
    "        \n",
    "        y_pred_threshold= self.predictions\n",
    "        \n",
    "        for ithreshold in [self.threshold_plot_confusion_matrix_sex]:\n",
    "            y_pred_threshold[self.predictions >= ithreshold] = 1                \n",
    "            y_pred_threshold[self.predictions < ithreshold] = 0\n",
    "\n",
    "            \n",
    "            itps, ifps, ifns, itns = 0, 0, 0, 0\n",
    "            \n",
    "\n",
    "            TPS, FPS, FNS, TNS = self.csv_test.iloc[0:0], self.csv_test.iloc[0:0], self.csv_test.iloc[0:0], self.csv_test.iloc[0:0]\n",
    "            \n",
    "            for i in range(len(y_pred_threshold)):\n",
    "                pred = 0 if int(y_pred_threshold[i]) == 0 else 1\n",
    "                    \n",
    "                if int(pred) == 1 and int(self.y_true[i]) == 1:\n",
    "                    TPS.loc[itps, :]=self.csv_test.loc[i, :]\n",
    "                    itps=itps+1\n",
    "\n",
    "                if int(pred) == 1 and int(self.y_true[i]) == 0:\n",
    "                    FPS.loc[ifps, :]=self.csv_test.loc[i, :]\n",
    "                    ifps = ifps+1                  \n",
    "                    \n",
    "                if int(pred)== 0 and int(self.y_true[i]) == 1:\n",
    "                    FNS.loc[ifns, :]=self.csv_test.loc[i, :]\n",
    "                    ifns = ifns+1     \n",
    "\n",
    "                if int(pred) == 0 and int(self.y_true[i]) == 0:\n",
    "                    TNS.loc[itns, :]=self.csv_test.loc[i, :]\n",
    "                    itns = itns+1\n",
    "                    \n",
    "        TPS.to_csv(path_list_tps_fps_fns_tns+'/TPS.csv', index = False)\n",
    "        FPS.to_csv(path_list_tps_fps_fns_tns+'/FPS.csv', index = False)\n",
    "        FNS.to_csv(path_list_tps_fps_fns_tns+'/FNS.csv', index = False)\n",
    "        TNS.to_csv(path_list_tps_fps_fns_tns+'/TNS.csv', index = False)\n",
    "        \n",
    "        save_images=  str(input(\"Do you want to save TPS, FPS, FNS y TNS images?  - (options: Yes, No): \"))\n",
    "        if save_images == 'Yes': self.save_images_fpfntptn(path_list_tps_fps_fns_tns)\n",
    "        \n",
    "    def folders(self):\n",
    "        if not os.path.exists(self.model_directory + '/'): os.mkdir(self.model_directory + '/')  \n",
    "        if not os.path.exists(self.model_directory + '/'+self.type_image +'/'): os.mkdir(self.model_directory + '/'+self.type_image +'/')  \n",
    "        if not os.path.exists(self.model_directory + '/'+self.type_image +'/'+self.model_conv +'/'): os.mkdir(self.model_directory + '/'+self.type_image +'/'+self.model_conv +'/')  \n",
    "        if not os.path.exists(self.model_directory + '/'+self.type_image +'/'+self.model_conv +'/'+self.model_type+'/'): os.mkdir(self.model_directory + '/'+self.type_image +'/'+self.model_conv +'/'+self.model_type+'/')\n",
    "        \n",
    "        self.path_to_save_metrics = self.model_directory + '/'+self.type_image +'/'+self.model_conv +'/'+self.model_type+'/'\n",
    "        \n",
    "        if self.I_want_to_train_models == 'Yes': self.model_parameters = 'MODELDETECTION_FREEZE'+self.str(self.freeze)+'_TOPMODEL' + self.top_m + '_CLASSES' + str(self.neurons_last_layer) + '_INITIALIZER_SEED' + str(self.initializer_seed) + '_OPTIMIZER' + self.topt + '_lr' + str(self.lr) + '_LOSSF' + self.lossf + '_BATCHSIZE' + str(self.batch_size) + '_EPOCHS' + str(self.epochs)\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.model_parameters = str(input(\"Name of the model you want to load (without .hdf5): \"))\n",
    "        print(f\"Name: {self.model_parameters}\")\n",
    "        self.model = tf.keras.models.load_model(self.path_to_save_metrics + self.model_parameters+'.hdf5')   \n",
    "        \n",
    "        \n",
    "    def model_predict(self):\n",
    "        self.folders()\n",
    "        if self.I_want_to_train_models == 'No': self.load_model() \n",
    "        \n",
    "        for ithreshold in list(range(1,10,1)):\n",
    "            self.threshold_plot_confusion_matrix_sex = float(input(\"What threshold do you want to get list of FP, FN, TP and TN?  - (options: 0.1-0.9): \"))\n",
    "            self.threshold = ithreshold/10\n",
    "            self.Error_metrics = False\n",
    "            \n",
    "                \n",
    "            if (self.model_type == 'Hybrid' and self.type_image == '2D') or self.type_image == '3D':\n",
    "                if self.model_type == 'Hybrid':\n",
    "                    test_data = [self.X_test_image, self.X_test_dataf] \n",
    "                elif self.type_image == '3D':\n",
    "                    test_data = self.X_test_image \n",
    "                self.predictions = self.model.predict(test_data, verbose=1)\n",
    "                self.y_true = np.array(self.y_test)\n",
    "\n",
    "                \n",
    "            elif (self.model_type == 'Images' and self.type_image == '2D'):\n",
    "                self.predictions = self.model.predict_generator(self.test_generator, steps= self.test_generator.n // self.test_generator.batch_size+1, verbose=1)\n",
    "                self.y_true = np.array(self.test_generator.labels)\n",
    "            \n",
    "            self.get_auc()\n",
    "            \n",
    "            if self.AUC > self.p_to_save:\n",
    "                self.get_metrics()\n",
    "\n",
    "                if self.threshold==self.threshold_plot_confusion_matrix_sex: self.list_fp_fn_tp_tn()\n",
    "                \n",
    "                \n",
    "     \n",
    "    def get_auc(self):\n",
    "        self.y_pred=self.predictions[:,0]\n",
    "        self.AUC = roc_auc_score(y_true=self.y_true, y_score=self.y_pred)\n",
    "        self.model_name = 'AUC'+str(round(self.AUC, 4)) + self.model_parameters\n",
    "        \n",
    "        if self.AUC > self.p_to_save: \n",
    "            self.roc_curve()\n",
    "            self.bootstrapping(metrics = 'AUC')\n",
    "        \n",
    "        \n",
    "    def get_metrics(self):      \n",
    "        \n",
    "        self.y_pred_threshold = self.predictions[:,0]\n",
    "            \n",
    "        self.y_pred_threshold[self.predictions[:,0] >= self.threshold] = 1                \n",
    "        self.y_pred_threshold[self.predictions[:,0] < self.threshold] = 0\n",
    "\n",
    "        self.bootstrapping(metrics = 'METRICS')\n",
    "        \n",
    "            \n",
    "        if self.Error_metrics == False:                \n",
    "            if self.I_want_to_train_models=='Yes':\n",
    "                keras.models.save_model(self.model, self.path_to_save_metrics + self.model_name + '.hdf5')\n",
    "                pd.DataFrame.from_dict(self.history.history).to_csv(self.path_to_save_metrics + self.model_name +\".csv\",index=False)\n",
    "                self.plot_learning_curves()\n",
    "        else:\n",
    "            print(\"Error, ZeroDivisionError with all thresholds.\")\n",
    "\n",
    "                \n",
    "    def roc_curve(self):\n",
    "        fpr, tpr, _ = roc_curve(self.y_true, self.predictions[:,0])\n",
    "        plt.plot(fpr, tpr, linewidth=2)\n",
    "        plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Baseline')\n",
    "        plt.title('ROC Curve', size=12)\n",
    "        plt.xlabel('False Positive Rate', size=10)\n",
    "        plt.ylabel('True Positive Rate', size=10)\n",
    "        plt.savefig(self.path_to_save_metrics + 'CURVEROC_' + self.model_name + '.png')\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "    def plot_confusion_matrix(self, path_name_boost, normalize=False, title=None, cmap=plt.cm.Blues, classes= {'0': 'Health', '1': 'ICH'}):\n",
    "        if not title:\n",
    "            if normalize:\n",
    "                title = 'Normalized confusion matrix'\n",
    "            else:\n",
    "                title = 'Confusion matrix, without normalization'\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(self.y_true, self.y_pred_threshold)\n",
    "        \n",
    "        if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            \n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        \n",
    "        # We want to show all ticks...\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               # ... and label them with the respective list entries\n",
    "               xticklabels=classes, yticklabels=classes,\n",
    "               title=title,\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "        plt.grid(False)\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        ax.figure.savefig(path_name_boost+'.png')\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    def bootstrapping(self, metrics = 'AUC', confidence = 0.95, n_bootstraps = 1000, threshold = 0.9):\n",
    "        \n",
    "        rng_seed= np.random.RandomState(42) #definimos semilla de aleatorización.         \n",
    "        \n",
    "        if metrics == 'METRICS': \n",
    "            bootstrapped_sensitivity= []\n",
    "            bootstrapped_specificity= []\n",
    "            bootstrapped_precission= []\n",
    "            bootstrapped_NPV= []  \n",
    "            bootstrapped_accuracy= []\n",
    "            bootstrapped_f1_score= []\n",
    "            bootstrapped_f2_score= [] \n",
    "                \n",
    "        elif metrics == 'AUC':\n",
    "            bootstrapped_roc_auc = []\n",
    "            \n",
    "                \n",
    "        for i in range(n_bootstraps): #en cada boostrap subsamplea el test y saca una AUC. \n",
    "            index= rng_seed.randint(0, self.y_true.shape[0], self.y_true.shape[0])   #0: cual es el número más pequeño que puede salir, es cero porque nuestros índices empiezan el cero. El número máximo es el índice más alto del array, osea, 256. El tercer número es el número de número que quieres que te salgan por cada vez, también 256.  \n",
    "            if len(np.unique(self.y_true[index])) < 2:  #si menor de 2, no vale. np.unique devuelve un array con los valores diferentes que tú tienes. Ej. hombre o mujer tiene 1 y 2 de np unique o F y M. \n",
    "                continue\n",
    "                \n",
    "            if metrics == 'METRICS': \n",
    "                tps, fps, fns, tns = [], [], [], []\n",
    "\n",
    "                for i in index:\n",
    "                    pred = 0 if int(self.y_pred_threshold[i]) == 0 else 1\n",
    "                    \n",
    "                    if int(pred) == 1 and int(self.y_true[i]) == 1:\n",
    "                        tps.append(self.y_pred_threshold[i])\n",
    "                    if int(pred) == 1 and int(self.y_true[i]) == 0:\n",
    "                        fps.append(self.y_pred_threshold[i]) \n",
    "                    if int(pred)== 0 and int(self.y_true[i]) == 1:\n",
    "                        fns.append(self.y_pred_threshold[i]) \n",
    "                    if int(pred) == 0 and int(self.y_true[i]) == 0:\n",
    "                        tns.append(self.y_pred_threshold[i]) \n",
    "\n",
    "                tp= len(tps)\n",
    "                fp= len(fps)\n",
    "                fn= len(fns)\n",
    "                tn= len(tns)\n",
    "\n",
    "                \n",
    "                try:\n",
    "                    sensitivity= tp/(tp+fn)\n",
    "                    specificity= tn/(tn+fp)\n",
    "                    precission= tp/(tp+fp)\n",
    "                    NPV=tn/(tn+fn)\n",
    "                    accuracy= (tp+tn)/(tp+fn+fp+tn)\n",
    "                    f1_score= 2*sensitivity*precission/(sensitivity+precission)\n",
    "                    f2_score= 5*sensitivity*precission/(sensitivity+4*precission)\n",
    "                except ZeroDivisionError:\n",
    "                    self.Error_metrics = True\n",
    "                    return \n",
    "\n",
    "            \n",
    "                bootstrapped_sensitivity.append(sensitivity)\n",
    "                bootstrapped_specificity.append(specificity)\n",
    "                bootstrapped_precission.append(precission)\n",
    "                bootstrapped_NPV.append(NPV)\n",
    "                bootstrapped_accuracy.append(accuracy)\n",
    "                bootstrapped_f1_score.append(f1_score)\n",
    "                bootstrapped_f2_score.append(f2_score)\n",
    "                \n",
    "            elif metrics == 'AUC':\n",
    "                roc_auc= roc_auc_score(self.y_true[index], self.y_pred[index])  #images y predicciones. \n",
    "                bootstrapped_roc_auc.append(roc_auc)\n",
    "                \n",
    "\n",
    "        if metrics == 'METRICS': \n",
    "            bootstrapped_sensitivity= np.array(bootstrapped_sensitivity)\n",
    "            bootstrapped_sensitivity.sort()\n",
    "            bootstrapped_specificity= np.array(bootstrapped_specificity)\n",
    "            bootstrapped_specificity.sort()\n",
    "            bootstrapped_precission= np.array(bootstrapped_precission)\n",
    "            bootstrapped_precission.sort()\n",
    "            bootstrapped_NPV= np.array(bootstrapped_NPV)\n",
    "            bootstrapped_NPV.sort()\n",
    "            bootstrapped_accuracy= np.array(bootstrapped_accuracy)\n",
    "            bootstrapped_accuracy.sort()\n",
    "            bootstrapped_f1_score= np.array(bootstrapped_f1_score)\n",
    "            bootstrapped_f1_score.sort()\n",
    "            bootstrapped_f2_score= np.array(bootstrapped_f2_score)\n",
    "            bootstrapped_f2_score.sort()\n",
    "\n",
    "\n",
    "            b_sensitivity= np.average(bootstrapped_sensitivity)\n",
    "            lower_sensitivity= bootstrapped_sensitivity[int(((1-confidence)/2) * len(bootstrapped_sensitivity))]\n",
    "            upper_sensitivity= bootstrapped_sensitivity[int((confidence + ((1-confidence)/2)) * len(bootstrapped_sensitivity))]\n",
    "            b_specificity= np.average(bootstrapped_specificity)\n",
    "            lower_specificity= bootstrapped_specificity[int(((1-confidence)/2) * len(bootstrapped_specificity))]\n",
    "            upper_specificity= bootstrapped_specificity[int((confidence + ((1-confidence)/2)) * len(bootstrapped_specificity))]\n",
    "            b_precission= np.average(bootstrapped_precission)\n",
    "            lower_precission= bootstrapped_precission[int(((1-confidence)/2) * len(bootstrapped_precission))]\n",
    "            upper_precission= bootstrapped_precission[int((confidence + ((1-confidence)/2)) * len(bootstrapped_precission))]\n",
    "            b_NPV= np.average(bootstrapped_NPV)\n",
    "            lower_NPV= bootstrapped_NPV[int(((1-confidence)/2) * len(bootstrapped_NPV))]\n",
    "            upper_NPV= bootstrapped_NPV[int((confidence + ((1-confidence)/2)) * len(bootstrapped_NPV))]\n",
    "            b_accuracy= np.average(bootstrapped_accuracy)\n",
    "            self.accuracy = round(b_accuracy, 4)\n",
    "            lower_accuracy= bootstrapped_accuracy[int(((1-confidence)/2) * len(bootstrapped_accuracy))]\n",
    "            upper_accuracy= bootstrapped_accuracy[int((confidence + ((1-confidence)/2)) * len(bootstrapped_accuracy))]\n",
    "            b_f1_score= np.average(bootstrapped_f1_score)\n",
    "            lower_f1_score= bootstrapped_f1_score[int(((1-confidence)/2) * len(bootstrapped_f1_score))]\n",
    "            upper_f1_score= bootstrapped_f1_score[int((confidence + ((1-confidence)/2)) * len(bootstrapped_f1_score))]\n",
    "            b_f2_score= np.average(bootstrapped_f2_score)\n",
    "            lower_f2_score= bootstrapped_f2_score[int(((1-confidence)/2) * len(bootstrapped_f2_score))]\n",
    "            upper_f2_score= bootstrapped_f2_score[int((confidence + ((1-confidence)/2)) * len(bootstrapped_f2_score))]  \n",
    "\n",
    "\n",
    "            print('Sensitivity=%.3f, CI: lower=%.3f, upper=%.3f'%(b_sensitivity, lower_sensitivity, upper_sensitivity))\n",
    "            print('Specificity=%.3f, CI: lower=%.3f, upper=%.3f'%(b_specificity, lower_specificity, upper_specificity))\n",
    "            print('Precission=%.3f, CI: lower=%.3f, upper=%.3f'%(b_precission, lower_precission, upper_precission))\n",
    "            print('NPV=%.3f, CI: lower=%.3f, upper=%.3f'%(b_NPV, lower_NPV, upper_NPV))\n",
    "            print('Acurracy=%.3f, CI: lower=%.3f, upper=%.3f'%(self.accuracy, lower_accuracy, upper_accuracy))\n",
    "            print('F1_score=%.3f, CI: lower=%.3f, upper=%.3f'%(b_f1_score, lower_f1_score, upper_f1_score))\n",
    "            print('F2_score=%.3f, CI: lower=%.3f, upper=%.3f'%(b_f2_score, lower_f2_score, upper_f2_score))\n",
    "\n",
    "            productos = [\n",
    "            ('Sensitivity', b_sensitivity, lower_sensitivity, upper_sensitivity),\n",
    "            ('Specificity', b_specificity, lower_specificity, upper_specificity),\n",
    "            ('Precission', b_precission, lower_precission, upper_precission),\n",
    "            ('NPV', b_NPV, lower_NPV, upper_NPV),\n",
    "            ('Acurracy', self.accuracy, lower_accuracy, upper_accuracy),\n",
    "            ('F1_score', b_f1_score, lower_f1_score, upper_f1_score),\n",
    "            ('F2_score', b_f2_score, lower_f2_score, upper_f2_score)]\n",
    "            \n",
    "        elif metrics == 'AUC':\n",
    "            sorted_roc_auc_scores= np.array(bootstrapped_roc_auc) #convertimos en array la lista de las diferentes AUCs, para utilizar la función sort y ordenarlas.\n",
    "            sorted_roc_auc_scores.sort()  # ordenamos de tal forma que tenemos una curva de gauss, la media estará en medio. \n",
    "\n",
    "\n",
    "            roc_auc_bootstraping= np.average(np.array(bootstrapped_roc_auc))\n",
    "            lower_roc_auc_difference= sorted_roc_auc_scores[int(((1-confidence)/2) * len(sorted_roc_auc_scores))]\n",
    "            upper_roc_auc_difference= sorted_roc_auc_scores[int((confidence + ((1-confidence)/2)) * len(sorted_roc_auc_scores))]    \n",
    "\n",
    "            print('ROC_AUC=%.3f, CI: lower=%.3f, upper=%.3f'%(roc_auc_bootstraping, lower_roc_auc_difference, upper_roc_auc_difference))\n",
    "\n",
    "            productos = [('ROC_AUC', roc_auc_bootstraping, lower_roc_auc_difference, upper_roc_auc_difference)]\n",
    "            \n",
    "\n",
    "        wb = openpyxl.Workbook()\n",
    "        hoja = wb.active\n",
    "            \n",
    "        # Crea la fila del encabezado con los títulos\n",
    "        hoja.append(('Metrics','Value', 'CI - lower', 'CI - upper'))\n",
    "\n",
    "        for producto in productos:\n",
    "            hoja.append(producto)\n",
    "            path_name_boost= self.path_to_save_metrics + '/BOOST_'+metrics+'_'+self.model_name\n",
    "            if metrics == 'METRICS': path_name_boost= path_name_boost+'_threshold'+str(self.threshold)+'_ACC'+str(self.accuracy)\n",
    "            \n",
    "            wb.save(path_name_boost+'.xlsx')\n",
    "            read_file = pd.read_excel(path_name_boost+'.xlsx')\n",
    "            read_file.to_csv(path_name_boost+'.csv', index = None, header=True)\n",
    "            \n",
    "            if metrics == 'METRICS': self.plot_confusion_matrix(path_name_boost)      \n",
    "        \n",
    "\n",
    "    def print_data (self):\n",
    "        # Si se quiere obtener información del modelo, pasar True, con cualquier otro valor no se imprime\n",
    "        if self.print_report == True:\n",
    "            print('Model_type: ', self.model_type, '  -  Model_conv: ', self.model_conv )\n",
    "            print('\\n Model_top: ', self.top_m, '\\n- nclasses: ', str(self.neurons_last_layer))\n",
    "            print('\\n Compilation: ', self.topt, '\\n- lr: ' + str(self.lr), '\\n- lossf ' + self.lossf)\n",
    "            print(self.model.summary())\n",
    "            print('\\n Model_fit: \\n- batchsize: ' + str(self.batch_size), '\\n- epochs: ' + str(self.epochs), '\\n- initializer_seed: ' + str(self.initializer_seed))\n",
    "            print('\\n AUC Model: ', self.AUC)\n",
    "\n",
    "    def inputs(self):\n",
    "        print('\\n[INFO] INPUTS')\n",
    "        self.topt = str(input(\"Optimizer:  - (options: Adadelta, Adam, SGD, Adagrad)\"))\n",
    "        self.top_m = str(input(\"Top-model:  - (options: GMP, GAP, FD)\"))\n",
    "        self.lr = float(input(\"Learning-rate: \"))\n",
    "        self.batch_size = int(input(\"Batch-size: \"))\n",
    "        self.epochs = int(input(\"Epoch: \"))\n",
    "        \n",
    "    def My_model_runall(self):\n",
    "        \n",
    "        if self.I_want_to_train_models == 'Yes': self.inputs()\n",
    "            \n",
    "        print('\\n[INFO] LOADING DATA')\n",
    "        self.load_data()\n",
    "        \n",
    "        if self.I_want_to_train_models == 'Yes':\n",
    "            \n",
    "            print('\\n[INFO] CREATE MODEL')\n",
    "            self.base_model()\n",
    "            self.model_top()\n",
    "\n",
    "            print('\\n[INFO] COMPILE MODEL')\n",
    "            self.model_compilation()\n",
    "\n",
    "            print('\\n[INFO] TRAINING MODEL')\n",
    "            self.model_fit()\n",
    "            \n",
    "        \n",
    "        print('\\n[INFO] EVALUATING MODEL')\n",
    "        self.model_predict()\n",
    "        \n",
    "        print('\\n[INFO] REPORT')\n",
    "        if self.I_want_to_train_models == 'Yes': self.print_data()\n",
    "\n",
    "        \n",
    "        # Clean GPU memory\n",
    "        del self.model\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebf2dc-615c-4108-980b-86f5a1670d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS\n",
    "itrainpredict = str(input(\"Do you want to train a model?:  - (options: No, Yes)\"))\n",
    "itype_image = str(input(\"3D Images or 2D Images:  - (options: 2D, 3D)\"))\n",
    "imodel_conv = str(input(\"What type of model?:  - (options: CSIC, VGG16)\"))\n",
    "imodel_type=  str(input(\"Hybrid or only Images?:  - (options: Hybrid, Images)\"))\n",
    "    \n",
    "if (itype_image == '3D' and imodel_conv != 'CSIC'):\n",
    "    print('Model unavailable')\n",
    "    #sys.exit()    \n",
    "\n",
    "    \n",
    "My_model= My_Custom_Model(\n",
    "                                                            I_want_to_train_models = itrainpredict,\n",
    "\n",
    "                                                            path_csv= '/home/jovyan/IMAGE_PREPROCESSING_2D_3D/DIGITAL_CSIC_ICH/ICH_DETECTION/'+itype_image+'/CSV/' ,\n",
    "                                                            path_images= '/home/jovyan/GITHUB_ICH_PROGNOSIS/DIGITAL CSIC  ICH/ICH_DETECTION/'+itype_image+'/PREPROCESSED IMAGES/ALL_IMAGES/',\n",
    "\n",
    "                                                            img_width= 128,\n",
    "                                                            img_height= 128,\n",
    "                                                            dataAug = False,\n",
    "\n",
    "                                                            #Hyperparameters\n",
    "                                                            loss_function= 'binary_crossentropy',\n",
    "                                                            \n",
    "                                                            #Model\n",
    "                                                            type_image = itype_image,\n",
    "                                                            model_conv= imodel_conv, \n",
    "                                                            model_type= imodel_type, \n",
    "                    \n",
    "                                                            freeze= None, #Just for vgg16 --> True or False or None\n",
    "                                                            drop = 0.5,\n",
    "                                                            neurons_last_layer= 1,\n",
    "                                                            initializer_seed= 2,\n",
    "                                                            metrics= ['accuracy'],\n",
    "\n",
    "                                                            model_directory= '/home/jovyan/ICH_DETECTION/RESULTS/',\n",
    "                                                            patience= 5,\n",
    "\n",
    "                                                            print_report= False,                                                            \n",
    "                        \n",
    "                                                            p_to_save = 0.6,\n",
    "                        )\n",
    "\n",
    "\n",
    "My_model.My_model_runall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
